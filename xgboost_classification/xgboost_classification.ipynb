{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8aef668a-1884-444c-974f-904f6a1b7cd1",
   "metadata": {},
   "source": [
    "## XGBoost for Classification Problems\n",
    "______"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c070e25c-510e-47bb-b675-3c0b7f625eb7",
   "metadata": {},
   "source": [
    "- XGBoost is a library created for classification problems\n",
    "- Its speed and performance are unparalleled\n",
    "- It consistently outperforms any other algorithms aimed at supervised learning tasks\n",
    "- Requirements for XGBoost to achieve top performance:\n",
    "    - Numeric features should be scaled\n",
    "    - Categorical features should be encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095dc7da-8481-4196-8f64-dcfefa216f11",
   "metadata": {},
   "source": [
    "To show how these steps are done, we will be using the Rain in Australia dataset from Kaggle where we will predict whether it will rain today or not based on some weather measurements. In this section, we will focus on preprocessing by utilizing Scikit-Learn Pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f889dd4d-d8e1-40e7-b628-08184addfd8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Location</th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Evaporation</th>\n",
       "      <th>Sunshine</th>\n",
       "      <th>WindGustDir</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindDir9am</th>\n",
       "      <th>...</th>\n",
       "      <th>Humidity9am</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>Pressure9am</th>\n",
       "      <th>Pressure3pm</th>\n",
       "      <th>Cloud9am</th>\n",
       "      <th>Cloud3pm</th>\n",
       "      <th>Temp9am</th>\n",
       "      <th>Temp3pm</th>\n",
       "      <th>RainToday</th>\n",
       "      <th>RainTomorrow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-12-01</td>\n",
       "      <td>Albury</td>\n",
       "      <td>13.4</td>\n",
       "      <td>22.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>44.0</td>\n",
       "      <td>W</td>\n",
       "      <td>...</td>\n",
       "      <td>71.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1007.7</td>\n",
       "      <td>1007.1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.9</td>\n",
       "      <td>21.8</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-12-02</td>\n",
       "      <td>Albury</td>\n",
       "      <td>7.4</td>\n",
       "      <td>25.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WNW</td>\n",
       "      <td>44.0</td>\n",
       "      <td>NNW</td>\n",
       "      <td>...</td>\n",
       "      <td>44.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1010.6</td>\n",
       "      <td>1007.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.2</td>\n",
       "      <td>24.3</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-12-03</td>\n",
       "      <td>Albury</td>\n",
       "      <td>12.9</td>\n",
       "      <td>25.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WSW</td>\n",
       "      <td>46.0</td>\n",
       "      <td>W</td>\n",
       "      <td>...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1007.6</td>\n",
       "      <td>1008.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>23.2</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-12-04</td>\n",
       "      <td>Albury</td>\n",
       "      <td>9.2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NE</td>\n",
       "      <td>24.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>...</td>\n",
       "      <td>45.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1017.6</td>\n",
       "      <td>1012.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.1</td>\n",
       "      <td>26.5</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-12-05</td>\n",
       "      <td>Albury</td>\n",
       "      <td>17.5</td>\n",
       "      <td>32.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>41.0</td>\n",
       "      <td>ENE</td>\n",
       "      <td>...</td>\n",
       "      <td>82.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1010.8</td>\n",
       "      <td>1006.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>29.7</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date Location  MinTemp  MaxTemp  Rainfall  Evaporation  Sunshine  \\\n",
       "0  2008-12-01   Albury     13.4     22.9       0.6          NaN       NaN   \n",
       "1  2008-12-02   Albury      7.4     25.1       0.0          NaN       NaN   \n",
       "2  2008-12-03   Albury     12.9     25.7       0.0          NaN       NaN   \n",
       "3  2008-12-04   Albury      9.2     28.0       0.0          NaN       NaN   \n",
       "4  2008-12-05   Albury     17.5     32.3       1.0          NaN       NaN   \n",
       "\n",
       "  WindGustDir  WindGustSpeed WindDir9am  ... Humidity9am  Humidity3pm  \\\n",
       "0           W           44.0          W  ...        71.0         22.0   \n",
       "1         WNW           44.0        NNW  ...        44.0         25.0   \n",
       "2         WSW           46.0          W  ...        38.0         30.0   \n",
       "3          NE           24.0         SE  ...        45.0         16.0   \n",
       "4           W           41.0        ENE  ...        82.0         33.0   \n",
       "\n",
       "   Pressure9am  Pressure3pm  Cloud9am  Cloud3pm  Temp9am  Temp3pm  RainToday  \\\n",
       "0       1007.7       1007.1       8.0       NaN     16.9     21.8         No   \n",
       "1       1010.6       1007.8       NaN       NaN     17.2     24.3         No   \n",
       "2       1007.6       1008.7       NaN       2.0     21.0     23.2         No   \n",
       "3       1017.6       1012.8       NaN       NaN     18.1     26.5         No   \n",
       "4       1010.8       1006.0       7.0       8.0     17.8     29.7         No   \n",
       "\n",
       "   RainTomorrow  \n",
       "0            No  \n",
       "1            No  \n",
       "2            No  \n",
       "3            No  \n",
       "4            No  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "rain = pd.read_csv(\"data/weatherAUS.csv\")\n",
    "\n",
    "rain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1789305-0147-4291-aa19-50b0e7b354bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 145460 entries, 0 to 145459\n",
      "Data columns (total 23 columns):\n",
      " #   Column         Non-Null Count   Dtype  \n",
      "---  ------         --------------   -----  \n",
      " 0   Date           145460 non-null  object \n",
      " 1   Location       145460 non-null  object \n",
      " 2   MinTemp        143975 non-null  float64\n",
      " 3   MaxTemp        144199 non-null  float64\n",
      " 4   Rainfall       142199 non-null  float64\n",
      " 5   Evaporation    82670 non-null   float64\n",
      " 6   Sunshine       75625 non-null   float64\n",
      " 7   WindGustDir    135134 non-null  object \n",
      " 8   WindGustSpeed  135197 non-null  float64\n",
      " 9   WindDir9am     134894 non-null  object \n",
      " 10  WindDir3pm     141232 non-null  object \n",
      " 11  WindSpeed9am   143693 non-null  float64\n",
      " 12  WindSpeed3pm   142398 non-null  float64\n",
      " 13  Humidity9am    142806 non-null  float64\n",
      " 14  Humidity3pm    140953 non-null  float64\n",
      " 15  Pressure9am    130395 non-null  float64\n",
      " 16  Pressure3pm    130432 non-null  float64\n",
      " 17  Cloud9am       89572 non-null   float64\n",
      " 18  Cloud3pm       86102 non-null   float64\n",
      " 19  Temp9am        143693 non-null  float64\n",
      " 20  Temp3pm        141851 non-null  float64\n",
      " 21  RainToday      142199 non-null  object \n",
      " 22  RainTomorrow   142193 non-null  object \n",
      "dtypes: float64(16), object(7)\n",
      "memory usage: 25.5+ MB\n"
     ]
    }
   ],
   "source": [
    "rain.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14ec81a-aff1-4ad8-b27f-b1f5398efaf5",
   "metadata": {},
   "source": [
    "The dataset contains weather measures of 10 years from multiple weather stations in Australia. You can either predict whether it will rain tomorrow or today, so there are two targets in the dataset named RainToday, RainTomorrow.\n",
    "\n",
    "Since we will only be predicting for RainToday, we will drop the other one along with some other features that won't be necessary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5af1f7e-8174-4d67-83bc-3d8208982014",
   "metadata": {},
   "outputs": [],
   "source": [
    "rain.drop([\"Date\", \"Location\", \"RainTomorrow\", \"Rainfall\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffc87b6-0bc6-482a-9228-2806289974cf",
   "metadata": {},
   "source": [
    "Next, let’s deal with missing values starting by looking at their proportions in each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ff026c6-1eaf-4fde-8664-d72658f3afd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinTemp          0.010209\n",
       "MaxTemp          0.008669\n",
       "Evaporation      0.431665\n",
       "Sunshine         0.480098\n",
       "WindGustDir      0.070989\n",
       "WindGustSpeed    0.070555\n",
       "WindDir9am       0.072639\n",
       "WindDir3pm       0.029066\n",
       "WindSpeed9am     0.012148\n",
       "WindSpeed3pm     0.021050\n",
       "Humidity9am      0.018246\n",
       "Humidity3pm      0.030984\n",
       "Pressure9am      0.103568\n",
       "Pressure3pm      0.103314\n",
       "Cloud9am         0.384216\n",
       "Cloud3pm         0.408071\n",
       "Temp9am          0.012148\n",
       "Temp3pm          0.024811\n",
       "RainToday        0.022419\n",
       "dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_props = rain.isna().mean(axis=0)\n",
    "missing_props"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b0a4f5-76cc-4c6d-8fab-5fd984b60de0",
   "metadata": {},
   "source": [
    "If the proportion is higher than 40% we will drop the column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65c1f35a-8584-4b22-b744-1480f98f00e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Evaporation    0.431665\n",
       "Sunshine       0.480098\n",
       "Cloud3pm       0.408071\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "over_threshold = missing_props[missing_props >= 0.4]\n",
    "over_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f1ee77-2fcd-4a40-8984-e65aa139cc80",
   "metadata": {},
   "source": [
    "Three columns contain more than 40% missing values. We will drop them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d70ddc36-1cd8-4527-86e0-e73cfd1a7947",
   "metadata": {},
   "outputs": [],
   "source": [
    "rain.drop(over_threshold.index, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aef748d-7fb7-4318-8826-4b01e6df0092",
   "metadata": {},
   "source": [
    "Now, before we move on to pipelines, let’s divide the data into feature and target arrays beforehand:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3906a04a-ef1b-4e2b-82ed-538999915bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = rain.drop(\"RainToday\", axis=1)\n",
    "y = rain.RainToday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea344a3c-917d-4dfc-9d48-487dfcd89533",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.map(lambda x: 0 if x=='No' else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f289840a-a039-46ab-b742-51514d8e732c",
   "metadata": {},
   "source": [
    "Next, there are both categorical and numeric features. We will build two separate pipelines and combine them later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ac72a3-ce9e-41b7-ac65-f72bde9d9c03",
   "metadata": {},
   "source": [
    "For the categorical features, we will impute the missing values with the mode of the column and encode them with `One-Hot encoding`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45e909d5-50ab-4394-a241-ed08115d2a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "categorical_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"impute\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"oh-encode\", OneHotEncoder(handle_unknown=\"ignore\", sparse=False)),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12632b77-584f-4b56-83d5-664e8d957eb7",
   "metadata": {},
   "source": [
    "For the numeric features, I will choose the mean as an imputer and `StandardScaler` so that the features have 0 mean and a variance of 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5923401-c229-4855-b376-22bf7f3f74e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "numeric_pipeline = Pipeline(\n",
    "    steps=[(\"impute\", SimpleImputer(strategy=\"mean\")), \n",
    "           (\"scale\", StandardScaler())]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53137fa-f565-48dc-b68c-17463bd39bb6",
   "metadata": {},
   "source": [
    "Finally, we will combine the two pipelines with a column transformer. To specify which columns the pipelines are designed for, we should first isolate the categorical and numeric feature names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6aa44b07-20b2-4b89-bd5d-9d78b4b5de34",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = X.select_dtypes(exclude=\"number\").columns\n",
    "num_cols = X.select_dtypes(include=\"number\").columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f1374d-fa5d-4d7b-94db-17db3b059fcd",
   "metadata": {},
   "source": [
    "Next, we will input these along with their corresponding pipelines into a `ColumnTransFormer` instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13ce8305-3312-465f-bef7-1adc7039e665",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "full_processor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"numeric\", numeric_pipeline, num_cols),\n",
    "        (\"categorical\", categorical_pipeline, cat_cols),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8496d6f3-3365-4e4f-a904-70dd4727aac6",
   "metadata": {},
   "source": [
    "The full pipeline is finally ready. Now we'll add an `XGBoost` classifier.\n",
    "\n",
    "We can import it under its standard alias — xgb. For classification problems, the library provides XGBClassifier class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "097db48c-6831-4845-8c2f-277977a0af2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'xgboost.sklearn.XGBClassifier'>\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "xgb_cl = xgb.XGBClassifier()\n",
    "\n",
    "print(type(xgb_cl))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09e4590-99c4-491a-b4ef-1a92fc7bd764",
   "metadata": {},
   "source": [
    "Fortunately, the classifier follows the familiar fit-predict pattern of sklearn meaning we can freely use it as any sklearn model.\n",
    "\n",
    "Before we train the classifier, let’s preprocess the data and divide it into train and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa5f21f8-1ad7-45a4-89fa-95e376034cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocessing\n",
    "X_processed = full_processor.fit_transform(X)\n",
    "y_processed = SimpleImputer(strategy=\"most_frequent\").fit_transform(y.values.reshape(-1, 1))\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_processed, y_processed, stratify=y_processed, random_state=1121218)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968d77ba-11fb-41af-8989-39b7bfe84848",
   "metadata": {},
   "source": [
    "Since the target contains NaN, I imputed it by hand. Also, it is important to pass y_processed to stratify so that the split contains the same proportion of categories in both sets.\n",
    "\n",
    "Now, we fit the classifier with default parameters and evaluate its performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b909f02c-6ded-4f53-95f5-bd77ab070db4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8368761171456071"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Init classifier\n",
    "xgb_cl = xgb.XGBClassifier()\n",
    "\n",
    "# Fit\n",
    "xgb_cl.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "preds = xgb_cl.predict(X_test)\n",
    "\n",
    "# Score\n",
    "accuracy_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23387d3-4587-41fe-ae91-f7a8597e219d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
